{
    "abstract": "Gaussian process (GP) predictors are an important component of many
    Bayesian approaches to machine learning. However, even a
    straightforward implementation of Gaussian process regression (GPR)
    requires <i>O(n<sup>2</sup>)</i> space and <i>O(n<sup>3</sup>)</i> time for a data set of <i>n</i>
    examples. Several approximation methods have been proposed, but
    there is a lack of understanding of the relative merits of the
    different approximations, and in what situations they are most
    useful.  We recommend assessing the quality of the predictions
    obtained as a function of the compute time taken, and comparing to
    standard baselines (e.g., Subset of Data and FITC).
    We empirically investigate four different approximation algorithms on
    four different prediction problems, and make our code available to
    encourage future comparisons.",
    "authors": [
        "Krzysztof Chalupka",
        "Christopher K. I. Williams",
        "Iain Murray"
    ],
    "id": "chalupka13a",
    "issue": 10,
    "pages": [
        303,
        331
    ],
    "title": "A Framework for Evaluating Approximation Methods for Gaussian Process Regression",
    "volume": 14,
    "year": 2013
}