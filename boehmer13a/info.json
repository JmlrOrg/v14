{
    "abstract": "Linear <em>reinforcement learning</em> (RL) algorithms like <em> least-squares temporal difference learning</em> (LSTD) require <em> basis functions</em> that span <em>approximation spaces</em> of potential value functions. This article investigates methods to construct these bases from samples. We hypothesize that an ideal approximation spaces should encode <em>diffusion distances</em> and that <em>slow feature analysis</em> (SFA) constructs such spaces. To validate our hypothesis we provide theoretical statements about the LSTD value approximation error and induced metric of approximation spaces constructed by SFA and the state-of-the-art methods <em>Krylov bases</em> and <em>proto-value functions</em> (PVF). In particular, we prove that SFA minimizes the average (over all tasks in the same environment) bound on the above approximation error. Compared to other methods, SFA is very sensitive to sampling and can sometimes fail to encode the whole state space. We derive a novel <em>importance sampling</em> modification to compensate for this effect. Finally, the LSTD and <em>least squares policy iteration</em> (LSPI) performance of approximation spaces constructed by Krylov bases, PVF, SFA and PCA is compared in benchmark tasks and a visual robot navigation experiment (both in a realistic simulation and with a robot). The results support our hypothesis and suggest that (i) SFA provides <em>subspace-invariant</em> features for MDPs with <em> self-adjoint</em> transition operators, which allows strong guarantees on the approximation error, (ii) the modified SFA algorithm is best suited for LSPI in both discrete and continuous state spaces and (iii) approximation spaces encoding diffusion distances facilitate LSPI performance.",
    "authors": [
        "Wendelin B{{\\\"o}}hmer",
        "Steffen Gr{{\\\"u}}new{{\\\"a}}lder",
        "Yun Shen",
        "Marek Musial",
        "Klaus Obermayer"
    ],
    "id": "boehmer13a",
    "issue": 27,
    "pages": [
        2067,
        2118
    ],
    "title": "Construction of Approximation Spaces for Reinforcement Learning",
    "volume": 14,
    "year": 2013
}